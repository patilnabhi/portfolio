---
layout: post
title:  "TurtleBot SLAM (with RTAB-Map, Hand-Gestures, Face Recognition & AR Code Tracking)"
date:   2016-03-14 13:00:00
last_modified_at:  2016-03-14 13:00:00
excerpt: ""
categories: project
tags:  turtlebot, hand gesture recognition, face recognition, fisherfaces, OpenCv, robotics
image:
  feature: tbot.png
  topPosition: 0px
bgContrast: dark
bgGradientOpacity: darker
syntaxHighlighter: no
---
<h3>Goal:

* Navigation of TurtleBot using hand-gestures to find target locations marked with AR codes and/or to find a specific person using face-recognition

**Project Website:**  

* For a complete tutorial on launching the project with your TurtleBot, please refer to [http://github.com/patilnabhi/tbotnav]

**Demo:**  

<p><center><iframe width="1920" height="1080" src="https://www.youtube.com/embed/u7TcyaLekFg" frameborder="0" allowfullscreen></iframe></center></p>

**Objectives**

1. **[Hand-gesture recognition]:** Using a Kinect, OpenCV and ROS, develop an API to recognize number of fingers from 0 to 5  
<br>
2. **[Face recognition]:** Using a webcam, OpenCV and ROS, develop an API to create a database of people's faces and recognize faces in real-time  
<br>
3. **[Turtlebot SLAM]:** Using TurtleBot, Kinect and ROS, implement RTAB-Map (a RGB-D SLAM approach) to navigate TurtleBot in an unknown environment  
<br>
<!-- 4. **AR code tracking:** Using the ar_track_alvar package in ROS and a Kinect, track AR codes to determine their 'ids' and 'poses' relative to a frame -->

**Overview**

* The overall execution of the project is summarised in the flow-chart below:

<center><img style="border: solid" src="{{ site.baseurl }}/assets/images/posts/tbotnav/flow_chart.png" width="100%"/></center>


**Future work**
    
* **Object tracking:** Replace AR code tracking and get TurtleBot to find specific objects in the environment
* **RTAB-Map & beyond:** Explore the capabilities of RTAB-Map and RGB-D SLAM to make the navigation more robust
* **Simple is beautiful:** Improve the overall execution of the project to make it more user interactive by making it simpler/easier

*This project was completed as part of the MS in Robotics [(MSR)] program at Northwestern University.*

<!-- **References:** -->


[http://github.com/patilnabhi/tbotnav]: http://github.com/patilnabhi/tbotnav
[ROS]: http://www.ros.org/
[NU]: http://www.mccormick.northwestern.edu/robotics/
[OpenCV]: http://opencv.org/
[Rviz]: http://wiki.ros.org/rviz
[Hand-gesture recognition]: {{ site.baseurl }}hand-gestures
[Face recognition]: http://patilnabhi.github.io/portfolio/face-recognition
[Turtlebot SLAM]: http://github.com/patilnabhi/tbotnav
[(MSR)]: http://www.mccormick.northwestern.edu/robotics/meet-students/profiles-2015-2016/patil-abhishek.html