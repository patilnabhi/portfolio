---
layout: post
title:  "Turtlebot SLAM (with RTAB-Map, Hand-Gestures, Face Recognition & AR Code Tracking)"
date:   2016-03-14 13:00:00
last_modified_at:  2016-03-14 13:00:00
excerpt: ""
categories: project
tags:  turtlebot, hand gesture recognition, face recognition, fisherfaces, OpenCv, robotics
image:
  feature: tbot.png
  topPosition: 0px
bgContrast: dark
bgGradientOpacity: darker
syntaxHighlighter: no
---
**Project Website**
* For a complete tutorial on launching the project with your turtlebot, refer to [http://github.com/patilnabhi/tbotnav]

***This is a [ROS] project developed during the winter quarter at Northwestern University ([NU]) as part of M.S. in Robotics (MSR) program.
(ROS stands for Robot Operating System).***

**Demo**

<p><center><iframe width="1920" height="1080" src="https://www.youtube.com/embed/u7TcyaLekFg" frameborder="0" allowfullscreen></iframe></center></p>

**Goal**

* Navigation of turtlebot using hand-gestures to find target locations marked with AR codes and/or to find a specific person using face-recognition

**Objectives**

1. **[Hand-gesture recognition]:** Using a kinect, OpenCV and ROS, develop an API to recognize number of fingers from 0 to 5  
<br>
2. **[Face recognition]:** Using a webcam, OpenCV and ROS, develop an API to create a database of people's faces and recognize faces in real-time  
<br>
3. **[Turtlebot SLAM]:** Using turtlebot, kinect and ROS, implement RTAB-Map (a RGB-D SLAM approach) to navigate turtlebot in an unknown environment  
<br>
<!-- 4. **AR code tracking:** Using the ar_track_alvar package in ROS and a kinect, track AR codes to determine their 'ids' and 'poses' relative to a frame -->

**Overview**

* The overall execution of the project is summarised in the flow-chart below:

<center><img style="border: solid" src="{{ site.baseurl }}/assets/images/posts/tbotnav/flow_chart.png" width="100%"/></center>


**Future work**
    
* **Object tracking:** Replace AR code tracking and get turtlebot to find specific objects in the environment
* **RTAB-Map & beyond:** Explore the capabilities of RTAB-Map and RGB-D SLAM to make the navigation more robust
* **Simple is beautiful:** Improve the overall execution of the project to make it more user interactive by making it simpler/easier

<!-- **References:** -->


[http://github.com/patilnabhi/tbotnav]: http://github.com/patilnabhi/tbotnav
[ROS]: http://www.ros.org/
[NU]: http://www.mccormick.northwestern.edu/robotics/
[OpenCV]: http://opencv.org/
[Rviz]: http://wiki.ros.org/rviz
[Hand-gesture recognition]: http://patilnabhi.github.io/portfolio/hand-gestures
[Face recognition]: http://patilnabhi.github.io/portfolio/face-recognition
[Turtlebot SLAM]: http://github.com/patilnabhi/tbotnav